---
title: "Exploring Covid 19 data - Part 2"
date: 2020-04-26
tags: [data science, data visualization]
excerpt: "Data Science, Data Vis"
---

In [another post]({% post_url 2020-04-26-covid19-part1 %}) we stated the problem and now we'll show how we actually collected the data through **R** and how we created a data vis using **ggplot2**. The code is hosted on a (repository)[https://github.com/estevaovilela/covid-19] on GitHub.

The data concerns about confirmed or suspected deaths caused by Covid-19 in Brazil and it's provided by Brazilian Civil Registry Offices. We saw that the data is disaggregated by states, gender and age group in a JSON format in this link 'https://transparencia.registrocivil.org.br/api/covid?data_type=data_ocorrido&start_date=2020-01-01&end_date=2020-04-26&state=Todos&search=death-covid&groupBy=gender', like this:

{"chart":{"< 9":{"F":7},"10 - 19":{"M":24,"F":19},"20 - 29":{"F":31,"M":37},"30 - 39":{"M":116,"F":66},"40 - 49":{"F":132,"M":246},"50 - 59":{"M":364,"F":203},"60 - 69":{"M":604,"F":357},"70 - 79":{"M":672,"F":422},"80 - 89":{"F":416,"M":436},"90 - 99":{"M":123,"F":176},"> 100":{"M":5,"F":9}},"created_at":"26\/04\/2020 16:00"}

To read the data we use the function *fromJSON()* from the package *jsonlite*, passing as a parameter the url. In order to do this we create a function so we can go through each state in a daily basis:

```r
url_function <- function(state, start_date, end_date) {
  paste0("https://transparencia.registrocivil.org.br/api/covid?data_type=data_ocorrido&search=death-covid&state=",
         state,
         "&start_date=",
         start_date,
         "&end_date=",
         end_date,
         "&groupBy=gender")
}
```
The output from a request to the website looks like this:


There is an excellent [post](https://hendrikvanb.gitlab.io/2018/07/nested_data-json_to_tibble/) that explains how to parse data in JSON format using the function *unnest()* from *purrr* package, in a more 'tidy way'. We didn't have success using this approach, so tried another way: the output from the request is an object of type **list** and we can get into it's elements using brackets, in a more 'base R' way. Another detail is that the age groups are in the names of this list, so we have to use the function *names()* to extract it.

This how the data gathered look like:

This dataset is in .csv and is available for download in [GitHub]().

We want to do a pyramid chart faceted by the states and with a chronological approach. In order to do that we need a dataset with every possible combination of the attributes we want to use, in our case is: state, gender, age group and date. In addition, we want the pyramid to show cumulative cases.

To create this 'all combinations' data frame we used the function *cross_df()* from *purrr* package, and passed as parameters all the attributes in a list format. This [link](https://purrr.tidyverse.org/reference/cross.html) was useful for details of the function. Once we have that data frame we use `r left_join` to get the number of deaths in each day, the resulting NA's represents 0 deaths.

Finally, using *gganimate* we were able to generate the plot, that is a .gif actually. The package renders the plot in a gif or a video and it takes some time to do that, and it's [documentation](https://gganimate.com/articles/gganimate.html#rendering) clearly explains how to.

This is the Data Vis:

Would like to thank Eva Maerey for her [flipbook](https://evamaerey.github.io/little_flipbooks_library/taming_themes_in_ggplot/taming_ggplot_themes.html#1
) on **themes** in ggplot2.

At first intended to make two plots, one with the pyramid chart and another with a map. Then, discovered an excellent function watching Alex Engler presentation "Better DataViz in ggplot2: Tips, Tricks & Examples" in 2019 DC R Conference: *facet_geo*.

Link youtube: https://www.youtube.com/watch?v=h_QMd2d_o98&list=WL&index=17&t=646s

This function allows to facet the data in a geographically way like a choropleth map, but instead of coloring some polygon data, it arranges our facetted graph position each of the polygon in it's geographical position. The result combining *facet_geo* with *gganimate* wasn't that good, but with only one frame it looks like this:
